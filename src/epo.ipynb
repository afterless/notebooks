{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/afterless/projects/notebooks/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import dataclasses\n",
    "import time\n",
    "import contextlib\n",
    "from typing import Callable, Dict, List, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions\n",
    "import torch.nn.functional as F\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_if_not_none(a, b):\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    else:\n",
    "        return torch.cat([a, b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xentropy(logits, input_ids):\n",
    "    logits_offset = logits[:, :-1]\n",
    "    return (\n",
    "        torch.nn.CrossEntropyLoss(reduction=\"none\")(\n",
    "            logits_offset.reshape(-1, logits_offset.shape[-1]),\n",
    "            input_ids[:, 1:].reshape(-1),\n",
    "        )\n",
    "        .view(*logits_offset.shape[:2])\n",
    "        .mean(dim=-1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class State:\n",
    "    ids: torch.Tensor\n",
    "    target: torch.Tensor\n",
    "    xentropy: torch.Tensor\n",
    "    final_token: torch.Tensor\n",
    "    token_grads: torch.Tensor\n",
    "    extra: Dict[str, torch.Tensor]\n",
    "\n",
    "    def cat(self, other):\n",
    "        return State(\n",
    "            ids=torch.cat([self.ids, other.ids], dim=0),\n",
    "            target=torch.cat([self.target, other.target], dim=0),\n",
    "            xentropy=torch.cat([self.xentropy, other.xentropy], dim=0),\n",
    "            final_token=torch.cat([self.final_token, other.final_token], dim=0),\n",
    "            token_grads=cat_if_not_none(self.token_grads, other.token_grads),\n",
    "            extra = {k: cat_if_not_none(self.extra[k], other.extra[k]) for k in self.extra},\n",
    "        )\n",
    "    \n",
    "    def subset(self, keep):\n",
    "        return State(\n",
    "            ids=self.ids[keep],\n",
    "            target=self.target[keep],\n",
    "            xentropy=self.xentropy[keep],\n",
    "            final_token=self.final_token[keep],\n",
    "            token_grads=self.token_grads[keep.to(\"cpu\")] if self.token_grads is not None else None,\n",
    "            extra = {k: self.extra[k][keep] for k in self.extra},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/llm-attacks/llm-attacks/blob/main/llm_attacks/gcg/gcg_attack.py\n",
    "def token_grads(\n",
    "    model: torch.nn.Module,\n",
    "    cache_run: Callable,\n",
    "    input_ids: torch.Tensor,\n",
    "    x_penalty: torch.Tensor,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute gradients with respect to one-hot encoded input tokens. This is a\n",
    "    infinitesimal approximation to the token influence on the loss so it's a\n",
    "    very noisy indicator of which tokens might reduce loss.\n",
    "    \"\"\"\n",
    "    embed = model.get_input_embeddings()\n",
    "\n",
    "    token_grads = torch.empty(\n",
    "        (input_ids.shape[0], input_ids.shape[1], embed.num_embeddings),\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    loss = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    xentropy = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    target = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    final_token = torch.empty(input_ids.shape[0], device=model.device, dtype=torch.long)\n",
    "    extra = dict()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        model.zero_grad()\n",
    "\n",
    "        for i in range(0, input_ids.shape[0], batch_size):\n",
    "            imax = min(i + batch_size, input_ids.shape[0])\n",
    "\n",
    "            # using a one hot matrix as input to the model gives us gradients with\n",
    "            # respect to potential input tokens.\n",
    "            one_hot = F.one_hot(\n",
    "                input_ids[i:imax].clone(), num_classes=embed.num_embeddings\n",
    "            ).to(embed.weight.dtype)\n",
    "            one_hot.requires_grad = True\n",
    "\n",
    "            cache = cache_run(inputs_embeds=torch.matmul(one_hot, embed.weight))\n",
    "\n",
    "            logits_offset = cache[\"logits\"][:, :-1]\n",
    "            this_xentropy = (\n",
    "                -(torch.log_softmax(logits_offset, dim=-1) * one_hot[:, 1:])\n",
    "                .sum(dim=-1)\n",
    "                .mean(dim=-1)\n",
    "            )\n",
    "\n",
    "            this_loss = -cache[\"target\"] + this_xentropy * x_penalty[i:imax]\n",
    "            this_loss.sum().backward()\n",
    "\n",
    "            loss[i:imax] = this_loss\n",
    "            target[i:imax] = cache[\"target\"]\n",
    "            xentropy[i:imax] = this_xentropy\n",
    "            final_token[i:imax] = cache[\"logits\"][:, -1, :].argmax(dim=-1)\n",
    "            token_grads[i:imax] = one_hot.grad\n",
    "\n",
    "            for k in cache:\n",
    "                if k not in [\"target\", \"logits\"]:\n",
    "                    e = cache[k]\n",
    "                    if k not in extra:\n",
    "                        extra[k] = torch.empty(\n",
    "                            (input_ids.shape[0], *e.shape[1:]),\n",
    "                            dtype=e.dtype,\n",
    "                            device=e.device,\n",
    "                        )\n",
    "                    extra[k][i:imax] = e\n",
    "\n",
    "            # important to zero out gradients here to release memory\n",
    "            model.zero_grad()\n",
    "\n",
    "    return State(input_ids, target, xentropy, final_token, token_grads, extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class History:\n",
    "    \"\"\"\n",
    "    The `epo` function returns a History objet that contains the full history of the\n",
    "    population members at each iteration.\n",
    "    \"\"\"\n",
    "    # The token ids for each population member at each iteration.\n",
    "    ids: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The cross-entropy loss for each population member at each iteration.\n",
    "    xentropy: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The target objective for each popultion member at each iteration.\n",
    "    target: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The indices of the population members that were retained at each iteration.\n",
    "    keep: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The runtime for each iteration.\n",
    "    runtime: List = dataclasses.field(default_factory=lambda: [])\n",
    "\n",
    "    def subset(self, slc):\n",
    "        \"\"\"\n",
    "        Return a History object sliced along the iteration dimension.\n",
    "        \"\"\"\n",
    "        return History(\n",
    "            self.ids[slc],\n",
    "            self.xentropy[slc],\n",
    "            self.target[slc],\n",
    "            self.keep[slc],\n",
    "            self.runtime[slc],\n",
    "        )\n",
    "\n",
    "    def _insert(self, new_ids, target, xentropy, keep, runtime):\n",
    "        self.ids.append(new_ids.cpu().numpy())\n",
    "        self.target.append(target.cpu().numpy())\n",
    "        self.xentropy.append(xentropy.cpu().numpy())\n",
    "        self.keep.append(keep.cpu().numpy())\n",
    "        self.runtime.append(runtime)\n",
    "\n",
    "    def _finalize(self):\n",
    "        self.ids = np.stack(self.ids, axis=0)\n",
    "        self.target = np.stack(self.target, axis=0)\n",
    "        self.xentropy = np.stack(self.xentropy, axis=0)\n",
    "        self.keep = np.stack(self.keep, axis=0)\n",
    "        self.runtime = np.array(self.runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector:\n",
    "   def __init__(\n",
    "           self,\n",
    "           model: torch.nn.Module,\n",
    "           cache_run: Callable,\n",
    "           X: torch.Tensor,\n",
    "           batch_size: int,\n",
    "   ):\n",
    "         self.model = model\n",
    "         self.cache_run = cache_run\n",
    "         self.X = X\n",
    "         self.batch_size = batch_size\n",
    "\n",
    "class GradientSelector(Selector):\n",
    "    uses_gradient = True\n",
    "\n",
    "    def setup(self, input_ids: torch.Tensor):\n",
    "        return token_grads(\n",
    "            self.model,\n",
    "            self.cache_run,\n",
    "            input_ids,\n",
    "            x_penalty=self.X,\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "    \n",
    "    def mutate(self, state, source_idx, input_ids, topk):\n",
    "        # when just flipping, the current token gradient falls out of the \n",
    "        # topk operation, so we can just use the negative new token grad\n",
    "        topk_grad = (-state.token_grads).topk(k=topk, dim=-1)\n",
    "        pos = torch.randint(\n",
    "            low=0,\n",
    "            high=input_ids.shape[1],\n",
    "            size=(input_ids.shape[0],),\n",
    "            device = input_ids.device,\n",
    "        )\n",
    "        token_idx = torch.randint(\n",
    "            low=0,\n",
    "            high=topk,\n",
    "            size=(input_ids.shape[0],),\n",
    "            device=input_ids.device,\n",
    "        )\n",
    "        input_ids[torch.arange(input_ids.shape[0]), pos] = topk_grad.indices.to(\n",
    "            input_ids.device\n",
    "        )[source_idx, pos, token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness(\n",
    "        model: torch.nn.Module,\n",
    "        cache_run: Callable,\n",
    "        input_ids: torch.Tensor,\n",
    "        batch_size: int,\n",
    "):\n",
    "    target = torch.empty(input_ids.shape[0], dtype=torch.float, device=input_ids.device)\n",
    "    xentropy = torch.empty(\n",
    "        input_ids.shape[0], dtype=torch.float, device=input_ids.device\n",
    "    )\n",
    "    final_token = torch.empty(\n",
    "        input_ids.shape[0], dtype=torch.long, device=input_ids.device\n",
    "    )\n",
    "    extra = dict()\n",
    "    for i in range(0, input_ids.shape[0], batch_size):\n",
    "        imax = min(i + batch_size, input_ids.shape[0])\n",
    "        mini_batch = cache_run(input_ids=input_ids[i:imax])\n",
    "        target[i:imax] = mini_batch[\"target\"]\n",
    "        xentropy[i:imax] = calc_xentropy(mini_batch[\"logits\"], input_ids[i:imax])\n",
    "        final_token[i:imax] = mini_batch[\"logits\"][:, -1, :].argmax(dim=-1)\n",
    "\n",
    "        for k in mini_batch:\n",
    "            if k not in [\"target\", \"logits\"]:\n",
    "                e = mini_batch[k]\n",
    "                if k not in extra:\n",
    "                    extra[k] = torch.empty(\n",
    "                        (input_ids.shape[0], *e.shape[1:]),\n",
    "                        dtype=e.dtype,\n",
    "                        device=e.device,\n",
    "                    )\n",
    "                extra[k][i:imax] = e\n",
    "\n",
    "    return State(input_ids, target, xentropy, final_token, None, extra)\n",
    "\n",
    "def pareto_callback(\n",
    "        cache_run: Callable,\n",
    "        model: torch.nn.Module,\n",
    "        tokenizer: transformers.PreTrainedTokenizer,\n",
    "        x_penalty_min: float,\n",
    "        x_penalty_max: float,\n",
    "):\n",
    "    def f(i, state, last_runtime, history, final=False):\n",
    "        if last_runtime is not None:\n",
    "            print(\"runtime: {:.2f} seconds\".format(last_runtime))\n",
    "        print(f\"\\nbeginning step {i}, current pareto frontier prompts:\")\n",
    "        last_idx = None\n",
    "        Xvs = torch.exp(\n",
    "            torch.linspace(\n",
    "                np.log(x_penalty_min / 10.0), np.log(x_penalty_max * 10.0), 200\n",
    "            )\n",
    "        ).to(model.device)\n",
    "        loss = -state.target[None] + Xvs[:, None] * state.xentropy[None]\n",
    "        idxs = loss.argmin(dim=1)\n",
    "        for i in range(len(Xvs)):\n",
    "            idx = idxs[i]\n",
    "            if idx == last_idx:\n",
    "                continue\n",
    "            text = tokenizer.decode(state.ids[idx])\n",
    "            last_token = tokenizer.decode(state.final_token[idx])\n",
    "            print(\n",
    "                f\"penalty={Xvs[i]:.2f} xentropy={state.xentropy[idx]:.2f} target={state.target[idx]:.2f} {repr(text + '[' + last_token + ']')}\"\n",
    "            )\n",
    "            last_idx = idx\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def epo(\n",
    "    cache_run: Callable,\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    seq_len: int = 12,\n",
    "    population_size: int = 8,\n",
    "    iters: int = 300,\n",
    "    explore_per_pop: int = 32,\n",
    "    batch_size: int = 8,\n",
    "    topk: int = 512,\n",
    "    mutation_method: str = \"gradient\",\n",
    "    x_penalty_min: float = 1.0 / 10.0,\n",
    "    x_penalty_max: float = 10.0,\n",
    "    restart_frequency: int = 50,\n",
    "    restart_xentropy: float = 2.0,\n",
    "    restart_xentropy_max_mult: float = 3.0,\n",
    "    seed: int = 0,\n",
    "    initial_ids: torch.Tensor = None,\n",
    "    history: History = None,\n",
    "    catch_keyboard_interrupt: bool = False,\n",
    "    callback: Union[Callable, bool] = None,\n",
    "    always_recompute_gradients: bool = False,\n",
    ") -> History:\n",
    "    \"\"\"\n",
    "    Run the EPO algorithm. See the paper for details\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cache_run\n",
    "        A callable that accepts either input_ids or input_embeds and returns a\n",
    "        dictionary containing the `target` and the logits for each token position\n",
    "    model\n",
    "    tokenizer\n",
    "    population_size, optional\n",
    "        The population to keep at each iteration, by default 8\n",
    "    iters, optional\n",
    "        Number of iterations to run EPO, by default 1000\n",
    "    explore_per_pop, optional\n",
    "        Number of children per population member per iteration, by default 32\n",
    "    batch_size, optional\n",
    "        GPU batch size, by default 8\n",
    "    topk, optional\n",
    "        When selecting token replacements, we select the `topk` tokens by\n",
    "        gradient magnitude and choose uniformly at random between those, by\n",
    "        default 32.\n",
    "    mutation_method, optional\n",
    "        research, ignore, by default \"gradient\"\n",
    "     x_penalty_min, optional\n",
    "        The minimum cross-entropy penalty, by default 1.0/16.0\n",
    "    x_penalty_max, optional\n",
    "        The maximum cross-entropy penalty, by default 16.0\n",
    "    restart_frequency, optional\n",
    "        How often do we reset the Pareto frontier, by default 50\n",
    "    restart_xentropy, optional\n",
    "        When we reset the Pareto frontier, we select a population member that\n",
    "        is optimal according to a cross-entropy penalty that is selected\n",
    "        uniformly at random in the domain\n",
    "        [restart_xentropy / restart_xentropy_max_mult,\n",
    "         restart_xentropy * restart_xentropy_max_mult],\n",
    "        restart_xentropy is by default 2.0\n",
    "    restart_xentropy_max_mult, optional\n",
    "        See the explanation for restart_xentropy, by default 3.0\n",
    "    seed, optional\n",
    "        Random seed used for initialization, by default 0\n",
    "    initial_ids, optional\n",
    "        The initial token ids to begin optimizing from. If None, the initial\n",
    "        token ids will be selected randomly, by default None\n",
    "    history, optional\n",
    "        The history of an EPO run that we want to continue, by default None\n",
    "    catch_keyboard_interrupt, optional\n",
    "        Should we catch keyboard interrupts and end the EPO loop?, by default False\n",
    "    callback, optional\n",
    "        A function called at the beginning of each iteration, by default None\n",
    "    always_recompute_gradients, optional\n",
    "        If a population member is retained across an iteration, we default to\n",
    "        not recomputing that population member's token gradients. If your\n",
    "        cache_run stores internal state that changes, you may want to override\n",
    "        this behavior and recompute gradients every iteration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A History object containing the full history of the EPO run.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    explore_size = population_size * explore_per_pop\n",
    "    device = model.device\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    if x_penalty_min is None or x_penalty_max is None:\n",
    "        X = torch.zeros(population_size, device=model.device)\n",
    "    else:\n",
    "        X = torch.exp(\n",
    "            torch.linspace(\n",
    "                np.log(x_penalty_min), np.log(x_penalty_max), population_size\n",
    "            )\n",
    "        ).to(model.device)\n",
    "    \n",
    "    if callback is None:\n",
    "        callback = pareto_callback(\n",
    "            cache_run,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            X.min().item(),\n",
    "            X.max().item(),\n",
    "        )\n",
    "    elif callback is False:\n",
    "        callback = lambda *args: True\n",
    "    \n",
    "\n",
    "    ### history and initial_ids ###\n",
    "    if history is not None:\n",
    "        if initial_ids is not None:\n",
    "            raise ValueError(\"Cannot specify both history and initial_ids\")\n",
    "        initial_ids = history.ids[-1, history.keep[-1]]\n",
    "    elif initial_ids is not None:\n",
    "        history = History()\n",
    "        input_ids = initial_ids.to(model.device)\n",
    "        if initial_ids.shape[1] != seq_len:\n",
    "            raise ValueError(f\"initial_ids must have shape [*, {seq_len}]\")\n",
    "    else:\n",
    "        history = History()\n",
    "        input_ids = torch.randint(\n",
    "            low=0, high=tokenizer.vocab_size, size=(population_size, seq_len)\n",
    "        ).to(model.device)\n",
    "    \n",
    "\n",
    "    ### choose an update selection method ###\n",
    "    if mutation_method == \"gradient\":\n",
    "        selector_type = GradientSelector\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mutation_method: {mutation_method}\")\n",
    "    selector = selector_type(model, cache_run, X, batch_size)\n",
    "\n",
    "    ### Run the EPO loop: ###\n",
    "    if hasattr(cache_run, \"setup\"):\n",
    "        cache_run.setup(input_ids)\n",
    "    state = selector.setup(input_ids)\n",
    "\n",
    "    # We use a try/except blok so that we can catch keyboard interrupts and\n",
    "    # still return results. This is useful for interactive use when it's nice\n",
    "    # to launch with a larger `iters` parameter and then just stop the run when\n",
    "    # the results look good enough.\n",
    "    try:\n",
    "        for i in range(iters):\n",
    "            # 1) Report\n",
    "            terminate_flag = callback(i, state, time.time() - start, history)\n",
    "            if (\n",
    "                (isinstance(terminate_flag, str) and terminate_flag == \"terminate\")\n",
    "                or (isinstance(terminate_flag, torch.Tensor) and terminate_flag.item())\n",
    "                or (isinstance(terminate_flag, bool) and terminate_flag)\n",
    "            ):\n",
    "                if i == 0:\n",
    "                    history._insert(\n",
    "                        state.ids,\n",
    "                        state.target,\n",
    "                        state.xentropy,\n",
    "                        torch.arange(state.ids.shape[0]),\n",
    "                        time.time() - start,\n",
    "                    )\n",
    "                break\n",
    "            else:\n",
    "                start = time.time()\n",
    "            recompute_gradients = always_recompute_gradients or (\n",
    "                terminate_flag == \"recompute_gradients\"\n",
    "            )\n",
    "\n",
    "            # 2) Birth children from parents\n",
    "            source_idx = torch.cat(\n",
    "                (\n",
    "                    torch.arange(state.ids.shape[0], device=device).repeat(\n",
    "                        explore_size // state.ids.shape[0]\n",
    "                    ),\n",
    "                    torch.arange(explore_size % state.ids.shape[0], device=device)\n",
    "                )\n",
    "            )\n",
    "            assert source_idx.shape[0] == explore_size\n",
    "            assert (source_idx < state.ids.shape[0]).all()\n",
    "\n",
    "            new_ids = state.ids[source_idx, :].clone()\n",
    "\n",
    "            # 3) Run the selector. This might be\n",
    "            #    - random\n",
    "            #    - gradient-based\n",
    "            #    - cosine-similarity-guided\n",
    "            selector.mutate(state, source_idx, new_ids, topk)\n",
    "\n",
    "            # 4) Evaluate fitness\n",
    "            new_state = evaluate_fitness(\n",
    "                model, cache_run, new_ids, batch_size=batch_size\n",
    "            )\n",
    "            all_state = state.cat(new_state)\n",
    "\n",
    "            # note that all_loss is a matrix with a row for each population\n",
    "            # member because each population member slot uses a different\n",
    "            # xentropy penalty.\n",
    "            all_loss = (\n",
    "                -all_state.target[None, :] + X[:, None] * all_state.xentropy[None, :]\n",
    "            )\n",
    "\n",
    "            # keep the population members with the lowest loss\n",
    "            keep = (-all_loss).argmax(dim=1).to(torch.int)\n",
    "\n",
    "            if i % restart_frequency == 0:\n",
    "                min_mult = 1.0 / restart_xentropy_max_mult\n",
    "                max_mult = restart_xentropy_max_mult\n",
    "                mult = min_mult + (max_mult - min_mult) * torch.rand(1).item()\n",
    "                restart_X = restart_xentropy * mult\n",
    "                restart_loss = -all_state.target + restart_xentropy * all_state.xentropy\n",
    "                print(f\"restarting with xentropy penalty of {restart_X:.2f}\")\n",
    "                keep[:] = restart_loss.argmin()\n",
    "\n",
    "            history._insert(\n",
    "                all_state.ids,\n",
    "                all_state.target,\n",
    "                all_state.xentropy,\n",
    "                keep,\n",
    "                time.time() - start,\n",
    "            )\n",
    "\n",
    "            # 5) Calculate gradients for the next iteration.\n",
    "            if i != iters - 1:\n",
    "                if selector.uses_gradient:\n",
    "                    if recompute_gradients:\n",
    "                        survived = torch.tensor([])\n",
    "                        new = keep\n",
    "                    else:\n",
    "                        survived = keep[keep < state.ids.shape[0]]\n",
    "                        new = keep[keep >= state.ids.shape[0]]\n",
    "                    if new.shape[0] > 0:\n",
    "                        state_new = selector.setup(all_state.ids[new])\n",
    "                    if survived.shape[0] > 0:\n",
    "                        state_survived = state.subset(survived)\n",
    "                        if new.shape[0] > 0:\n",
    "                            state = state_survived.cat(state_new)\n",
    "                        else:\n",
    "                            state = state_survived\n",
    "                    else:\n",
    "                        state = state_new\n",
    "                else:\n",
    "                    state = all_state.subset(keep)\n",
    "\n",
    "    # it's handy to sometimes be able to interrupt the loop and still get\n",
    "    # results!\n",
    "    except KeyboardInterrupt:\n",
    "        if catch_keyboard_interrupt:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    terminate_flag = callback(i, state, time.time() - start, history, final=True)\n",
    "\n",
    "    history._finalize()\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runner Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def add_fwd_hooks(module_hooks: List[Tuple[torch.nn.Module, Callable]]):\n",
    "    \"\"\"\n",
    "    Context manager for temporarily adding forward hooks to a model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module_hooks\n",
    "        A list of pairs: (module, fnc) The function will be registered as a\n",
    "            forward hook on the module\n",
    "    \"\"\"\n",
    "    try:\n",
    "        handles = []\n",
    "        for mod, hk in module_hooks:\n",
    "            handles.append(mod.register_forward_hook(hk))\n",
    "        yield\n",
    "    finally:\n",
    "        for h in handles:\n",
    "            h.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def does_retokenize(model, tokenizer, input_ids):\n",
    "    \"\"\"\n",
    "    Ensures that the input_ids are the same after tokenization and detokenization\n",
    "    to ensure target alignment (doesn't seem necessary however)\n",
    "    \"\"\"\n",
    "    good = torch.empty(input_ids.shape[0], dtype=bool).to(model.device)\n",
    "    input_strs = tokenizer.batch_decode(input_ids)\n",
    "    for i, s in enumerate(input_strs):\n",
    "        retokenized = tokenizer.encode(s, return_tensors=\"pt\").to(model.device)\n",
    "        if retokenized.shape[1] != input_ids.shape[1]:\n",
    "            good[i] = False\n",
    "        else:\n",
    "            good[i] = (retokenized[0] == input_ids[i]).all()\n",
    "        if not good[i]:\n",
    "            print(f\"bad input {i}: {s}\")\n",
    "    return good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_runner(model, tokenizer, layer, vector, check_retokenization=False):\n",
    "    def run(input_ids=None, inputs_embeds=None):\n",
    "        if input_ids is not None:\n",
    "            if check_retokenization:\n",
    "                good = does_retokenize(model, tokenizer, input_ids)\n",
    "            else:\n",
    "                good = torch.ones(input_ids.shape[0], dtype=bool).to(model.device)\n",
    "        else:\n",
    "            good = torch.ones(inputs_embeds.shape[0], dtype=bool).to(model.device)\n",
    "\n",
    "        out = {}\n",
    "\n",
    "        def get_target(module, input, output):\n",
    "            resid = input[0][:, -1]\n",
    "            std_resid = (resid - resid.mean(dim=-1, keepdim=True)) / resid.std(\n",
    "                dim=-1, keepdim=True\n",
    "            )\n",
    "            out[\"target\"] = std_resid @ vector\n",
    "\n",
    "        hooks = [\n",
    "            (model.gpt_neox.layers[layer], get_target),\n",
    "        ]\n",
    "\n",
    "        with add_fwd_hooks(hooks):\n",
    "            if input_ids is not None:\n",
    "                output = model(input_ids)\n",
    "            else:\n",
    "                output = model(inputs_embeds=inputs_embeds)\n",
    "\n",
    "        out[\"logits\"] = output.logits\n",
    "        out[\"target\"][~good] = -torch.finfo(out[\"target\"].dtype).max\n",
    "        return out\n",
    "\n",
    "    return run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(param_str=\"160m\"):\n",
    "    model_name = f\"EleutherAI/pythia-{param_str}-deduped\"\n",
    "\n",
    "    tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "        model_name,\n",
    "        token=\"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\",\n",
    "    )\n",
    "\n",
    "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        token=\"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\",\n",
    "    )\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = download(\"160m\")\n",
    "\n",
    "runner = residual_runner(model, tokenizer, 11, torch.ones(768))\n",
    "\n",
    "history = epo(\n",
    "    runner,\n",
    "    model,\n",
    "    tokenizer,\n",
    "    population_size=8,\n",
    "    iters=25,\n",
    "    explore_per_pop=8,\n",
    "    batch_size=8,\n",
    "    topk=512,\n",
    "    mutation_method=\"gradient\",\n",
    "    x_penalty_min=1.0 / 16.0,\n",
    "    x_penalty_max=16.0,\n",
    "    restart_frequency=50,\n",
    "    restart_xentropy=2.0,\n",
    "    restart_xentropy_max_mult=3.0,\n",
    "    seed=0,\n",
    "    history=None,\n",
    "    catch_keyboard_interrupt=False,\n",
    "    always_recompute_gradients=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
