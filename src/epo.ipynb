{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataclasses\n",
    "import time\n",
    "import contextlib\n",
    "from typing import Callable, Dict, List, Union, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributions\n",
    "import torch.nn.functional as F\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_if_not_none(a, b):\n",
    "    if a is None or b is None:\n",
    "        return None\n",
    "    else:\n",
    "        return torch.cat([a, b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class State:\n",
    "    ids: torch.Tensor\n",
    "    target: torch.Tensor\n",
    "    xentropy: torch.Tensor\n",
    "    final_token: torch.Tensor\n",
    "    token_grads: torch.Tensor\n",
    "    extra: Dict[str, torch.Tensor]\n",
    "\n",
    "    def cat(self, other):\n",
    "        return State(\n",
    "            ids=torch.cat([self.ids, other.ids], dim=0),\n",
    "            target=torch.cat([self.target, other.target], dim=0),\n",
    "            xentropy=torch.cat([self.xentropy, other.xentropy], dim=0),\n",
    "            final_token=torch.cat([self.final_token, other.final_token], dim=0),\n",
    "            token_grads=cat_if_not_none(self.token_grads, other.token_grads),\n",
    "            extra = {k: cat_if_not_none(self.extra[k], other.extra[k]) for k in self.extra},\n",
    "        )\n",
    "    \n",
    "    def subset(self, keep):\n",
    "        return State(\n",
    "            ids=self.ids[keep],\n",
    "            target=self.target[keep],\n",
    "            xentropy=self.xentropy[keep],\n",
    "            final_token=self.final_token[keep],\n",
    "            token_grads=self.token_grads[keep.to(\"cpu\")] if self.token_grads is not None else None,\n",
    "            extra = {k: self.extra[k][keep] for k in self.extra},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on https://github.com/llm-attacks/llm-attacks/blob/main/llm_attacks/gcg/gcg_attack.py\n",
    "def token_grads(\n",
    "    model: torch.nn.Module,\n",
    "    cache_run: Callable,\n",
    "    input_ids: torch.Tensor,\n",
    "    x_penalty: torch.Tensor,\n",
    "    batch_size: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute gradients with respect to one-hot encoded input tokens. This is a\n",
    "    infinitesimal approximation to the token influence on the loss so it's a\n",
    "    very noisy indicator of which tokens might reduce loss.\n",
    "    \"\"\"\n",
    "    embed = model.get_input_embeddings()\n",
    "\n",
    "    token_grads = torch.empty(\n",
    "        (input_ids.shape[0], input_ids.shape[1], embed.num_embeddings),\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "    loss = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    xentropy = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    target = torch.empty(input_ids.shape[0], device=model.device)\n",
    "    final_token = torch.empty(input_ids.shape[0], device=model.device, dtype=torch.long)\n",
    "    extra = dict()\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        model.zero_grad()\n",
    "\n",
    "        for i in range(0, input_ids.shape[0], batch_size):\n",
    "            imax = min(i + batch_size, input_ids.shape[0])\n",
    "\n",
    "            # using a one hot matrix as input to the model gives us gradients with\n",
    "            # respect to potential input tokens.\n",
    "            one_hot = F.one_hot(\n",
    "                input_ids[i:imax].clone(), num_classes=embed.num_embeddings\n",
    "            ).to(embed.weight.dtype)\n",
    "            one_hot.requires_grad = True\n",
    "\n",
    "            cache = cache_run(inputs_embeds=torch.matmul(one_hot, embed.weight))\n",
    "\n",
    "            logits_offset = cache[\"logits\"][:, :-1]\n",
    "            this_xentropy = (\n",
    "                -(torch.log_softmax(logits_offset, dim=-1) * one_hot[:, 1:])\n",
    "                .sum(dim=-1)\n",
    "                .mean(dim=-1)\n",
    "            )\n",
    "\n",
    "            this_loss = -cache[\"target\"] + this_xentropy * x_penalty[i:imax]\n",
    "            this_loss.sum().backward()\n",
    "\n",
    "            loss[i:imax] = this_loss\n",
    "            target[i:imax] = cache[\"target\"]\n",
    "            xentropy[i:imax] = this_xentropy\n",
    "            final_token[i:imax] = cache[\"logits\"][:, -1, :].argmax(dim=-1)\n",
    "            token_grads[i:imax] = one_hot.grad\n",
    "\n",
    "            for k in cache:\n",
    "                if k not in [\"target\", \"logits\"]:\n",
    "                    e = cache[k]\n",
    "                    if k not in extra:\n",
    "                        extra[k] = torch.empty(\n",
    "                            (input_ids.shape[0], *e.shape[1:]),\n",
    "                            dtype=e.dtype,\n",
    "                            device=e.device,\n",
    "                        )\n",
    "                    extra[k][i:imax] = e\n",
    "\n",
    "            # important to zero out gradients here to release memory\n",
    "            model.zero_grad()\n",
    "\n",
    "    return State(input_ids, target, xentropy, final_token, token_grads, extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class History:\n",
    "    \"\"\"\n",
    "    The `epo` function returns a History objet that contains the full history of the\n",
    "    population members at each iteration.\n",
    "    \"\"\"\n",
    "    # The token ids for each population member at each iteration.\n",
    "    ids: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The cross-entropy loss for each population member at each iteration.\n",
    "    xentropy: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The target objective for each popultion member at each iteration.\n",
    "    target: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The indices of the population members that were retained at each iteration.\n",
    "    keep: List = dataclasses.field(default_factory=lambda: [])\n",
    "    # The runtime for each iteration.\n",
    "    runtime: List = dataclasses.field(default_factory=lambda: [])\n",
    "\n",
    "    def subset(self, slc):\n",
    "        \"\"\"\n",
    "        Return a History object sliced along the iteration dimension.\n",
    "        \"\"\"\n",
    "        return History(\n",
    "            self.ids[slc],\n",
    "            self.xentropy[slc],\n",
    "            self.target[slc],\n",
    "            self.keep[slc],\n",
    "            self.runtime[slc],\n",
    "        )\n",
    "\n",
    "    def _insert(self, new_ids, target, xentropy, keep, runtime):\n",
    "        self.ids.append(new_ids.cpu().numpy())\n",
    "        self.target.append(target.cpu().numpy())\n",
    "        self.xentropy.append(xentropy.cpu().numpy())\n",
    "        self.keep.append(keep.cpu().numpy())\n",
    "        self.runtime.append(runtime)\n",
    "\n",
    "    def _finalize(self):\n",
    "        self.ids = np.stack(self.ids, axis=0)\n",
    "        self.target = np.stack(self.target, axis=0)\n",
    "        self.xentropy = np.stack(self.xentropy, axis=0)\n",
    "        self.keep = np.stack(self.keep, axis=0)\n",
    "        self.runtime = np.array(self.runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Selector:\n",
    "   def __init__(\n",
    "           self,\n",
    "           model: torch.nn.Module,\n",
    "           cache_run: Callable,\n",
    "           X: torch.Tensor,\n",
    "           batch_size: int,\n",
    "   ):\n",
    "         self.model = model\n",
    "         self.cache_run = cache_run\n",
    "         self.X = X\n",
    "         self.batch_size = batch_size\n",
    "\n",
    "class GradientSelector(Selector):\n",
    "    uses_gradient = True\n",
    "\n",
    "    def setup(self, input_ids: torch.Tensor):\n",
    "        return token_grads(\n",
    "            self.model,\n",
    "            self.cache_run,\n",
    "            input_ids,\n",
    "            x_penalty=self.X[:, input_ids.shape[0]],\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "    \n",
    "    def mutate(self, state, source_idx, input_ids, topk):\n",
    "        # when just flipping, the current token gradient falls out of the \n",
    "        # topk operation, so we can just use the negative new token grad\n",
    "        topk_grad = (-state.token_grads).topk(k=topk, dim=-1)\n",
    "        pos = torch.randint(\n",
    "            low=0,\n",
    "            high=input_ids.shape[1],\n",
    "            size=(input_ids.shape[0],),\n",
    "            device = input_ids.device,\n",
    "        )\n",
    "        token_idx = torch.randint(\n",
    "            low=0,\n",
    "            high=topk,\n",
    "            size=(input_ids.shape[0],),\n",
    "            device=input_ids.device,\n",
    "        )\n",
    "        input_ids[torch.arange(input_ids.shape[0]), pos] = topk_grad.indices.to(\n",
    "            input_ids.device\n",
    "        )[source_idx, pos, token_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def epo(\n",
    "    cache_run: Callable,\n",
    "    model: torch.nn.Module,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    seq_len: int = 12,\n",
    "    population_size: int = 8,\n",
    "    iters: int = 300,\n",
    "    explore_per_pop: int = 32,\n",
    "    batch_size: int = 8,\n",
    "    topk: int = 512,\n",
    "    mutation_method: str = \"gradient\",\n",
    "    x_penalty_min: float = 1.0 / 10.0,\n",
    "    x_penalty_max: float = 10.0,\n",
    "    restart_frequency: int = 50,\n",
    "    restart_xentropy: float = 2.0,\n",
    "    restart_xentropy_max_mult: float = 3.0,\n",
    "    seed: int = 0,\n",
    "    initial_ids: torch.Tensor = None,\n",
    "    history: History = None,\n",
    "    catch_keyboard_interrupt: bool = False,\n",
    "    callback: Union[Callable, bool] = None,\n",
    "    always_recompute_gradients: bool = False,\n",
    ") -> History:\n",
    "    \"\"\"\n",
    "    Run the EPO algorithm. See the paper for details\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cache_run\n",
    "        A callable that accepts either input_ids or input_embeds and returns a\n",
    "        dictionary containing the `target` and the logits for each token position\n",
    "    model\n",
    "    tokenizer\n",
    "    population_size, optional\n",
    "        The population to keep at each iteration, by default 8\n",
    "    iters, optional\n",
    "        Number of iterations to run EPO, by default 1000\n",
    "    explore_per_pop, optional\n",
    "        Number of children per population member per iteration, by default 32\n",
    "    batch_size, optional\n",
    "        GPU batch size, by default 8\n",
    "    topk, optional\n",
    "        When selecting token replacements, we select the `topk` tokens by\n",
    "        gradient magnitude and choose uniformly at random between those, by\n",
    "        default 32.\n",
    "    mutation_method, optional\n",
    "        research, ignore, by default \"gradient\"\n",
    "     x_penalty_min, optional\n",
    "        The minimum cross-entropy penalty, by default 1.0/16.0\n",
    "    x_penalty_max, optional\n",
    "        The maximum cross-entropy penalty, by default 16.0\n",
    "    restart_frequency, optional\n",
    "        How often do we reset the Pareto frontier, by default 50\n",
    "    restart_xentropy, optional\n",
    "        When we reset the Pareto frontier, we select a population member that\n",
    "        is optimal according to a cross-entropy penalty that is selected\n",
    "        uniformly at random in the domain\n",
    "        [restart_xentropy / restart_xentropy_max_mult,\n",
    "         restart_xentropy * restart_xentropy_max_mult],\n",
    "        restart_xentropy is by default 2.0\n",
    "    restart_xentropy_max_mult, optional\n",
    "        See the explanation for restart_xentropy, by default 3.0\n",
    "    seed, optional\n",
    "        Random seed used for initialization, by default 0\n",
    "    initial_ids, optional\n",
    "        The initial token ids to begin optimizing from. If None, the initial\n",
    "        token ids will be selected randomly, by default None\n",
    "    history, optional\n",
    "        The history of an EPO run that we want to continue, by default None\n",
    "    catch_keyboard_interrupt, optional\n",
    "        Should we catch keyboard interrupts and end the EPO loop?, by default False\n",
    "    callback, optional\n",
    "        A function called at the beginning of each iteration, by default None\n",
    "    always_recompute_gradients, optional\n",
    "        If a population member is retained across an iteration, we default to\n",
    "        not recomputing that population member's token gradients. If your\n",
    "        cache_run stores internal state that changes, you may want to override\n",
    "        this behavior and recompute gradients every iteration.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        A History object containing the full history of the EPO run.\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    explore_size = population_size * explore_per_pop\n",
    "    device = model.device\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    if x_penalty_min is None or x_penalty_max is None:\n",
    "        X = torch.zeros(population_size, device=model.device)\n",
    "    else:\n",
    "        X = torch.exp(\n",
    "            torch.linspace(\n",
    "                np.log(x_penalty_min), np.log(x_penalty_max), population_size\n",
    "            )\n",
    "        ).to(model.device)\n",
    "    \n",
    "    if callback is None:\n",
    "        callback = pareto_callback(\n",
    "            cache_run,\n",
    "            model,\n",
    "            tokenizer,\n",
    "            X.min().item(),\n",
    "            X.max().item(),\n",
    "        )\n",
    "    elif callback is False:\n",
    "        callback = lambda *args: True\n",
    "    \n",
    "\n",
    "    ### history and initial_ids ###\n",
    "    if history is not None:\n",
    "        if initial_ids is not None:\n",
    "            raise ValueError(\"Cannot specify both history and initial_ids\")\n",
    "        initial_ids = history.ids[-1, history.keep[-1]]\n",
    "    elif initial_ids is not None:\n",
    "        history = History()\n",
    "        input_ids = initial_ids.to(model.device)\n",
    "        if initial_ids.shape[1] != seq_len:\n",
    "            raise ValueError(f\"initial_ids must have shape [*, {seq_len}]\")\n",
    "    else:\n",
    "        history = History()\n",
    "        input_ids = torch.randint(\n",
    "            low=0, high=tokenizer.vocab_size, size=(population_size, seq_len)\n",
    "        ).to(model.device)\n",
    "    \n",
    "\n",
    "    ### choose an update selection method ###\n",
    "    if mutation_method == \"gradient\":\n",
    "        selector_type = GradientSelector\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown mutation_method: {mutation_method}\")\n",
    "    selector = selector_type(model, cache_run, X, batch_size)\n",
    "\n",
    "    ### Run the EPO loop: ###\n",
    "    if hasattr(cache_run, \"setup\"):\n",
    "        cache_run.setup(input_ids)\n",
    "    state = selector.setup(input_ids)\n",
    "\n",
    "    # We use a try/except blok so that we can catch keyboard interrupts and\n",
    "    # still return results. This is useful for interactive use when it's nice\n",
    "    # to launch with a larger `iters` parameter and then just stop the run when\n",
    "    # the results look good enough.\n",
    "    try:\n",
    "        for i in range(iters):\n",
    "            # 1) Report\n",
    "            terminate_flag = callback(i, state, time.time() - start, history)\n",
    "            if (\n",
    "                (isinstance(terminate_flag, str) and terminate_flag == \"terminate\")\n",
    "                or (isinstance(terminate_flag, torch.Tensor) and terminate_flag.item())\n",
    "                or (isinstance(terminate_flag, bool) and terminate_flag)\n",
    "            ):\n",
    "                if i == 0:\n",
    "                    history._insert(\n",
    "                        state.ids,\n",
    "                        state.target,\n",
    "                        state.xentropy,\n",
    "                        torch.arange(state.ids.shaoe[0]),\n",
    "                        time.time() - start,\n",
    "                    )\n",
    "                break\n",
    "            else:\n",
    "                start = time.time()\n",
    "            recompute_gradients = always_recompute_gradients or (\n",
    "                terminate_flag == \"recompute_gradients\"\n",
    "            )\n",
    "\n",
    "            # 2) Birth children from parents\n",
    "            source_idx = torch.cat(\n",
    "                (\n",
    "                    torch.arange(state.ids.shape[0], device=device).repeat(\n",
    "                        explore_size // state.ids.shape[0]\n",
    "                    ),\n",
    "                    torch.arange(explore_size % state.ids.shape[0], device=device)\n",
    "                )\n",
    "            )\n",
    "            assert source_idx.shape[0] == explore_size\n",
    "            assert (source_idx < state.ids.shape[0]).all()\n",
    "\n",
    "            new_ids = state.ids[source_idx, :].clone()\n",
    "\n",
    "            # 3) Run the selector. This might be\n",
    "            #    - random\n",
    "            #    - gradient-based\n",
    "            #    - cosine-similarity-guided\n",
    "            selector.mutate(state, source_idx, new_ids, topk)\n",
    "\n",
    "            # 4) Evaluate fitness\n",
    "            new_state = evaluate_fitness(\n",
    "                model, cache_run, new_ids, batch_size=batch_size\n",
    "            )\n",
    "            all_state = state.cat(new_state)\n",
    "\n",
    "            # note that all_loss is a matrix with a row for each population\n",
    "            # member because each population member slot uses a different\n",
    "            # xentropy penalty.\n",
    "            all_loss = (\n",
    "                -all_state.target[None, :] + X[:, None] * all_state.xentropy[None, :]\n",
    "            )\n",
    "            keep = (-all_loss).argmax(dim=1).to(torch.int)\n",
    "\n",
    "            if i % restart_frequency == 0:\n",
    "                min_mult = 1.0 / restart_xentropy_max_mult\n",
    "                max_mult = restart_xentropy_max_mult\n",
    "                mult = min_mult + (max_mult - min_mult) * torch.rand(1).item()\n",
    "                restart_X = restart_xentropy * mult\n",
    "                restart_loss = -all_state.target + restart_xentropy * all_state.xentropy\n",
    "                print(f\"restarting with xentropy penalty of {restart_X:.2f}\")\n",
    "                keep[:] = restart_loss.argmin()\n",
    "\n",
    "            history._insert(\n",
    "                all_state.ids,\n",
    "                all_state.target,\n",
    "                all_state.xentropy,\n",
    "                keep,\n",
    "                time.time() - start,\n",
    "            )\n",
    "\n",
    "            # 5) Calculate gradients for the next iteration.\n",
    "            if i != iters - 1:\n",
    "                if selector.uses_gradient:\n",
    "                    if recompute_gradients:\n",
    "                        survived = torch.tensor([])\n",
    "                        new = keep\n",
    "                    else:\n",
    "                        survived = keep[keep < state.ids.shape[0]]\n",
    "                        new = keep[keep >= state.ids.shape[0]]\n",
    "                    if new.shape[0] > 0:\n",
    "                        state_new = selector.setup(all_state.ids[new])\n",
    "                    if survived.shape[0] > 0:\n",
    "                        state_survived = state.subset(survived)\n",
    "                        if new.shape[0] > 0:\n",
    "                            state = state_survived.cat(state_new)\n",
    "                        else:\n",
    "                            state = state_survived\n",
    "                    else:\n",
    "                        state = state_new\n",
    "                else:\n",
    "                    state = all_state.subset(keep)\n",
    "\n",
    "    # it's handy to sometimes be able to interrupt the loop and still get\n",
    "    # results!\n",
    "    except KeyboardInterrupt:\n",
    "        if catch_keyboard_interrupt:\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    terminate_flag = callback(i, state, time.time() - start, history, final=True)\n",
    "\n",
    "    history._finalize()\n",
    "\n",
    "    return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
